{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wingate et al., AISTATS 2011, Algorithm 4\n",
    "---\n",
    "\n",
    "This paper by Wingate et al. proposes methods for recording, editing, and playing-back program traces, which become core components in PTO.\n",
    "\n",
    "Algorithm 4 in this paper is \"An illustration how the number and type of random choices can change.\" It is a short program which implicitly defines a distribution. \n",
    "\n",
    "The algorithm is (in Matlab):\n",
    "\n",
    "```\n",
    "1: m=poissrnd();\n",
    "2: for i=1:m\n",
    "3:     X(i) = gammarnd();\n",
    "4: end;\n",
    "5: for i=m+1:2*m\n",
    "6:     X(i) = randn;\n",
    "7: end;\n",
    "```\n",
    "\n",
    "It's intended as a distribution we might want to sample from, but for PTO purposes, let's define a fitness function on it -- `sum` -- and try to optimise it. The reason it's interesting for both Wingate et al. and for us is that the number `m` can change, which, in a naive implementation of program traces, would mean we were interpreting old trace material, previously used to sample from a gamma distribution, to sample from a normal, which would lead to bad results. Wingate et al. propose a better program trace implementation which avoids that, and which we therefore adopt in PTO.\n",
    "\n",
    "\n",
    "Implementing the problem for PTO\n",
    "---\n",
    "\n",
    "We first define the problem by defining the generator and fitness. Numpy provides the functions we need, but we are not using Numpy in our PTO generator code, for now (we will still use it for analysis, though). Python's standard library `random` module provides `gammavariate` and `normalvariate`, but it doesn't provide a Poisson variate, so we will implement that first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random, math\n",
    "def poissonvariate(lamb):\n",
    "    \"\"\"A method which will be slow for large lambda\n",
    "    From https://www.johndcook.com/blog/2010/06/14/generating-poisson-random-values/\n",
    "init:\n",
    "         Let L ← exp(−λ), k ← 0 and p ← 1.\n",
    "do:\n",
    "         k ← k + 1.\n",
    "         Generate uniform random number u in [0,1] and let p ← p × u.\n",
    "while p > L.\n",
    "return k − 1.\n",
    "\n",
    ">>> sum([poissonvariate(2.5) for _ in range(100)]) / 100.0\n",
    " -> a value near 2.5\n",
    "    \"\"\"\n",
    "    L = math.exp(-lamb)\n",
    "    k = 0\n",
    "    p = 1\n",
    "    while p > L:\n",
    "        k += 1\n",
    "        u = random.random()\n",
    "        p *= u\n",
    "    return k - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the generator closely mimics the original Matlab. Fitness is just `sum` as stated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator():\n",
    "    m = poissonvariate(10)\n",
    "    X = []\n",
    "    for i in range(m):\n",
    "        X.append(random.gammavariate(1, 1)) # alpha=1, beta=1\n",
    "    for i in range(m):\n",
    "        X.append(random.normalvariate(0, 1))\n",
    "    return X\n",
    "fitness = sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PTO import random, random_function, solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08358466201190759, 0.48143161905919946, 0.23853223262173445, 0.6421584913865963, 1.9571024812345295, 1.003821634311713, 0.20572271768498082, 4.417013897601947, 1.1649710388394199, 3.40100922232921, 1.0169776821846943, 0.060491490083636655, 1.9445634926319095, 0.376549334988143, 0.04109482285905346, 1.6239008268679758, 0.06666455317723373, 1.787518507864078, -2.141203655902093, -0.04143280744123887, -0.01911717380521149, 2.087048987735042, 2.0413363142739085, 1.4356382390520834, -0.8600251825586029, 0.49526039305865066, -0.4596633240588841, 0.06607474601206834, 1.872817007804373, 0.6173207547654004, 0.09706202473336747, 0.17148841631155817, 3.614169590582924, -0.8771742944702844]\n",
      "('fitness: ', 28.61270874383103)\n"
     ]
    }
   ],
   "source": [
    "ind, fit = solve(generator, fitness, solver=\"HC\", effort=1.0)\n",
    "print(ind)\n",
    "print(\"fitness: \", fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiments and Analysis\n",
    "---\n",
    "\n",
    "Next, we can do a large run and carry out some analysis on our results. \n",
    "We'll import functions provided by PTO, and also use scipy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PTO import compare_all, stat_summary\n",
    "import scipy.stats # only for post-run analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# compare_all: you can pass in sizes if needed, else None. It uses 'budget', not 'effort'.\n",
    "results = compare_all(fitness, [generator], sizes=None, \n",
    "                      methods=[\"HC\", \"LA\", \"EA\"], str_traces=[False, True], \n",
    "                      budget=10000, num_runs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 1**: Compare structured trace with linear, using hill-climbing: structured trace wins by far, of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 124.37 std 24.10 min 84.70 med 120.76 max 175.12\n",
      "mean 344.63 std 26.21 min 305.41 med 336.87 max 391.70\n",
      "Ttest_indResult(statistic=-18.559297810658265, pvalue=3.4870167422353794e-13)\n"
     ]
    }
   ],
   "source": [
    "d0, d1 = results[(None, False, 'generator', 'HC')], results[(None, True, 'generator', 'HC')]\n",
    "print(stat_summary(d0))\n",
    "print(stat_summary(d1))\n",
    "print(scipy.stats.ttest_ind(d0, d1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 2**: Compare hill-climbing with EA, using structured trace: HC wins!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 344.63 std 26.21 min 305.41 med 336.87 max 391.70\n",
      "mean 283.92 std 10.81 min 267.45 med 284.41 max 299.74\n",
      "Ttest_indResult(statistic=6.4230721300762541, pvalue=4.7942300292880871e-06)\n"
     ]
    }
   ],
   "source": [
    "d0, d1 = results[(None, True, 'generator', 'HC')], results[(None, True, 'generator', 'EA')]\n",
    "print(stat_summary(d0))\n",
    "print(stat_summary(d1))\n",
    "print(scipy.stats.ttest_ind(d0, d1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 3**: Compare HC with LAHC, using structured trace: HC wins! Stupid algorithms are good with the right representation?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 344.63 std 26.21 min 305.41 med 336.87 max 391.70\n",
      "mean 299.75 std 18.42 min 274.29 med 299.51 max 330.42\n",
      "Ttest_indResult(statistic=4.202115967932464, pvalue=0.00053569475594783056)\n"
     ]
    }
   ],
   "source": [
    "d0, d1 = results[(None, True, 'generator', 'HC')], results[(None, True, 'generator', 'LA')]\n",
    "print(stat_summary(d0))\n",
    "print(stat_summary(d1))\n",
    "print(scipy.stats.ttest_ind(d0, d1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions and future work\n",
    "---\n",
    "\n",
    "We have demonstrated the use of variable-length and heterogeneously-typed (ie different distributions) program traces, and how to carry out an experiment using PTO's provided tools, leading to some simple experiment results.\n",
    "\n",
    "Some ideas to test in future:\n",
    "\n",
    "* Try an alternative generator which interleaves the gamma and normal sampling.\n",
    "\n",
    "* Instead of setting `m` at the start, decide \"whether to stop\" at each\n",
    "iteration -- need to make sure `m` distribution is still Poisson, though.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
