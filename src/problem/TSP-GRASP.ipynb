{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PTO import random, solve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving TSP with GRASP emulated in PTO\n",
    "\n",
    "We'll use the same problem generator and fitness as when we solved TSP directly in PTO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "def randprob(n): \n",
    "    c = [[0 for x in range(n)] for x in range(n)] # initialise cost matrix\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                c[i][j] = 0 # zero diagonal\n",
    "            elif i > j:\n",
    "                c[i][j] = c[j][i] # symmetric matrix\n",
    "            else:\n",
    "                c[i][j] = random.expovariate(1) # more interesting than uniform weights\n",
    "    return c\n",
    "instance = randprob(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _fitness(perm, inst):\n",
    "    # note negative indexing trick to include final step (return to origin)\n",
    "    return -sum([inst[perm[i-1]][perm[i]] for i in range(0,len(perm))])\n",
    "fitness = lambda perm: _fitness(perm, instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the same generic GRASP generator as when we solved the ORDERING problem with GRASP emulated in PTO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randsol():\n",
    "  solution = empty_solution()\n",
    "  while(not complete(solution)):\n",
    "    #print(solution)\n",
    "    features = allowed_features(solution)\n",
    "    costs = {feat:cost_feature(solution, feat) for feat in features}\n",
    "    min_cost, max_cost = min(costs.values()), max(costs.values())\n",
    "    RCL = [feat for feat in features if costs[feat] <= min_cost + alpha * (max_cost - min_cost)]\n",
    "    #print(RCL)\n",
    "    selected_feature = random.choice(RCL) # only source of randomness\n",
    "    solution = add_feature(solution, selected_feature)\n",
    "  return solution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSP-specific functions for GRASP in PTO\n",
    "\n",
    "Finally, we fill in the functions used by `randsol` in a way appropriate to TSP. In fact, all of them are the same as in the ORDERING problem, except for the `cost_feature` functions and a small bookkeeping change in `allowed_features` (we will now count from 0 to n-1 instead of 1 to n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=len(instance)\n",
    "\n",
    "def empty_solution():\n",
    "  return []\n",
    "\n",
    "def complete(solution):\n",
    "  return len(solution)==n\n",
    "\n",
    "def allowed_features(solution):\n",
    "  all_items = range(n) # count from 0 to n-1\n",
    "  remaining_items = [item for item in all_items if item not in solution]\n",
    "  return remaining_items\n",
    "\n",
    "def cost_feature(solution, feat):\n",
    "  if len(solution) == 0:\n",
    "    # all cities cost nothing as start city. \n",
    "    # NB this will give a uniform random choice of start city,\n",
    "    # which is better than hardcoding it!\n",
    "    return 0 \n",
    "  last_item = solution[-1]\n",
    "  dist = instance[last_item][feat]\n",
    "  return dist\n",
    "\n",
    "def add_feature(solution, feat):\n",
    "  sol = solution[:] + [feat]\n",
    "  return sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can quickly test our approach without metaheuristic search. Again, we observe that the fully greedy approach is the best in this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random solution: fitness -3.774; [1, 8, 7, 5, 6, 4, 3, 0, 9, 2]\n",
      "Random solution: fitness -4.027; [7, 8, 1, 2, 6, 5, 3, 4, 9, 0]\n",
      "Random solution: fitness -4.027; [7, 8, 1, 2, 6, 5, 3, 4, 9, 0]\n",
      "Random solution: fitness -4.485; [2, 6, 5, 3, 4, 8, 7, 0, 9, 1]\n",
      "Random solution: fitness -4.027; [0, 7, 8, 1, 2, 6, 5, 3, 4, 9]\n",
      "===\n",
      "Random solution: fitness -7.167; [9, 8, 6, 2, 1, 4, 5, 3, 0, 7]\n",
      "Random solution: fitness -7.566; [5, 0, 9, 8, 4, 1, 2, 6, 7, 3]\n",
      "Random solution: fitness -6.255; [5, 9, 2, 6, 7, 1, 8, 4, 3, 0]\n",
      "Random solution: fitness -4.847; [9, 7, 6, 5, 0, 1, 8, 4, 3, 2]\n",
      "Random solution: fitness -7.659; [5, 6, 2, 4, 3, 1, 9, 7, 8, 0]\n",
      "===\n",
      "Random solution: fitness -16.852; [1, 3, 9, 2, 5, 7, 4, 0, 8, 6]\n",
      "Random solution: fitness -11.255; [9, 8, 5, 2, 7, 3, 1, 6, 4, 0]\n",
      "Random solution: fitness -10.988; [1, 4, 2, 6, 0, 8, 7, 9, 3, 5]\n",
      "Random solution: fitness -10.109; [8, 4, 3, 7, 2, 1, 5, 6, 9, 0]\n",
      "Random solution: fitness -13.887; [1, 9, 3, 6, 8, 7, 0, 2, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.0 # completely greedy\n",
    "\n",
    "for i in range(5):\n",
    "    x = randsol()\n",
    "    print(\"Random solution: fitness %.3f; %s\" % (fitness(x), str(x)))\n",
    "    \n",
    "print(\"===\")    \n",
    "    \n",
    "alpha = 0.5 # half way\n",
    "\n",
    "for i in range(5):\n",
    "    x = randsol()\n",
    "    print(\"Random solution: fitness %.3f; %s\" % (fitness(x), str(x)))\n",
    "    \n",
    "print(\"===\")    \n",
    "    \n",
    "alpha = 1.0 # completely random\n",
    "\n",
    "for i in range(5):\n",
    "    x = randsol()\n",
    "    print(\"Random solution: fitness %.3f; %s\" % (fitness(x), str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test with metaheuristic optimisation. This time, we observe that a less greedy approach in the generator ($\\alpha=0.5$) typically improves performance, at least with the HC solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha solver -fitness\n",
      "0 RS -3.004062971092426\n",
      "0 HC -3.004062971092426\n",
      "0 EA -3.004062971092426\n",
      "0.5 RS -2.818138494676305\n",
      "0.5 HC -2.8460228197790927\n",
      "0.5 EA -3.7527285496458207\n",
      "1.0 RS -3.8050944504310973\n",
      "1.0 HC -4.438373785243424\n",
      "1.0 EA -3.8785901485701535\n"
     ]
    }
   ],
   "source": [
    "print(\"alpha solver -fitness\")\n",
    "for alpha in [0, 0.5, 1.0]:\n",
    "    for solver in [\"RS\", \"HC\", \"EA\"]:\n",
    "        ind, fit = solve(randsol, fitness, solver=solver, budget=150)\n",
    "        print(alpha, solver, fit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
